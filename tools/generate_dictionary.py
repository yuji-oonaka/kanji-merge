import json
import os

# ==========================================
# è¨­å®š
# ==========================================
CURRENT_DIR = os.path.dirname(os.path.abspath(__file__))
INPUT_IDS_FILE = os.path.join(CURRENT_DIR, "ids.txt")
INPUT_JOYO_FILE = os.path.join(CURRENT_DIR, "joyo.txt")
CONFIG_FILE = os.path.join(CURRENT_DIR, "dictionary_config.json") # â˜…è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
OUTPUT_JSON_FILE = os.path.join(CURRENT_DIR, "../src/features/kanji-core/data/ids-map-auto.json")

def load_config():
    """è¨­å®šJSONã‚’èª­ã¿è¾¼ã‚€"""
    if not os.path.exists(CONFIG_FILE):
        print(f"âš ï¸ è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {CONFIG_FILE}")
        # ãƒ•ã‚¡ã‚¤ãƒ«ãŒãªã„å ´åˆã®æœ€ä½é™ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
        return set(["æ—¥", "æœˆ", "æœ¨"]), {}
    
    with open(CONFIG_FILE, "r", encoding="utf-8") as f:
        data = json.load(f)
        
    # JSONã‹ã‚‰ãƒªã‚¹ãƒˆã‚’èª­ã¿è¾¼ã¿ã€ã‚»ãƒƒãƒˆã«å¤‰æ›ï¼ˆæ¤œç´¢é«˜é€ŸåŒ–ã®ãŸã‚ï¼‰
    atomic_parts = set(data.get("atomic_parts", []))
    manual_overrides = data.get("manual_overrides", {})
    
    print(f"ğŸ“„ è¨­å®šèª­è¾¼å®Œäº†: åŸå­ãƒ‘ãƒ¼ãƒ„ {len(atomic_parts)}å€‹, æ‰‹å‹•è¨­å®š {len(manual_overrides)}å€‹")
    return atomic_parts, manual_overrides

def load_joyo_kanji(atomic_parts):
    """å¸¸ç”¨æ¼¢å­— + åŸºæœ¬çš„ãªã‚«ã‚¿ã‚«ãƒŠãªã©ã‚’èª­ã¿è¾¼ã‚€"""
    allowed_set = set(atomic_parts) # åŸå­ãƒ‘ãƒ¼ãƒ„ã¯æœ€åˆã‹ã‚‰è¨±å¯ãƒªã‚¹ãƒˆã«å…¥ã‚Œã‚‹
    try:
        with open(INPUT_JOYO_FILE, "r", encoding="utf-8") as f:
            for char in f.read():
                if char.strip(): allowed_set.add(char)
    except FileNotFoundError:
        pass
    
    # ã‚«ã‚¿ã‚«ãƒŠã‚„ä¸€èˆ¬çš„ãªè¨˜å·ã‚‚è¨±å¯
    for i in range(0x30A0, 0x30FF):
        allowed_set.add(chr(i))
    allowed_set.add("ã€†")
    allowed_set.add("ã€…")
    
    return allowed_set

def parse_ids_file(filepath):
    """IDSãƒ•ã‚¡ã‚¤ãƒ«ã‚’å…¨èª­ã¿è¾¼ã¿"""
    ids_db = {}
    try:
        with open(filepath, "r", encoding="utf-8") as f:
            for line in f:
                if line.startswith(";;"): continue
                parts = line.strip().split("\t")
                if len(parts) < 3: continue
                
                kanji = parts[1]
                structure = parts[2]
                components = [c for c in structure if c not in "â¿°â¿±â¿²â¿³â¿´â¿µâ¿¶â¿·â¿¸â¿¹â¿ºâ¿»" and c != kanji]
                ids_db[kanji] = components
    except FileNotFoundError:
        print("âŒ ids.txt ãŒã‚ã‚Šã¾ã›ã‚“")
        return {}
    return ids_db

def deep_decompose(kanji, ids_db, allowed_set, atomic_parts, depth=0):
    """å†å¸°çš„ã«åˆ†è§£ã—ã¦ã€çŸ¥ã£ã¦ã„ã‚‹æ–‡å­—(allowed_set)ã ã‘ã§æ§‹æˆã•ã‚ŒãŸãƒªã‚¹ãƒˆã‚’è¿”ã™"""
    if depth > 5: return None # æ·±ã™ããŸã‚‰è«¦ã‚ã‚‹

    # åŸå­ãƒ‘ãƒ¼ãƒ„ or å®šç¾©ãªã— -> ãã®ã¾ã¾
    if kanji in atomic_parts or kanji not in ids_db:
        return [kanji]

    components = ids_db[kanji]
    refined_components = []
    
    for comp in components:
        # åŸå­ãƒ‘ãƒ¼ãƒ„ã«å«ã¾ã‚Œã¦ã„ã‚‹ãªã‚‰ã€ãã‚Œä»¥ä¸Šåˆ†è§£ã›ãšã«æ¡ç”¨
        if comp in atomic_parts:
            refined_components.append(comp)
        elif comp in allowed_set:
             # çŸ¥ã£ã¦ã‚‹æ–‡å­—ã ã‘ã©åŸå­ãƒ‘ãƒ¼ãƒ„ã§ã¯ãªã„å ´åˆã€ã•ã‚‰ã«åˆ†è§£ãƒˆãƒ©ã‚¤
             # ï¼ˆã‚‚ã—åˆ†è§£ã§ããªã‘ã‚Œã°ãã®ã¾ã¾ä½¿ã†ï¼‰
            sub_comps = deep_decompose(comp, ids_db, allowed_set, atomic_parts, depth + 1)
            if sub_comps:
                refined_components.extend(sub_comps)
            else:
                refined_components.append(comp)
        else:
            # çŸ¥ã‚‰ãªã„æ–‡å­—ãªã‚‰ã€ã•ã‚‰ã«åˆ†è§£å¿…é ˆ
            sub_comps = deep_decompose(comp, ids_db, allowed_set, atomic_parts, depth + 1)
            if sub_comps:
                refined_components.extend(sub_comps)
            else:
                return None # åˆ†è§£ä¸èƒ½

    # ãƒ‘ãƒ¼ãƒ„æ•°ãŒå¤šã™ãã‚‹(5å€‹ä»¥ä¸Š)ã¯ã‚²ãƒ¼ãƒ çš„ã«å³ã—ã„ã®ã§NG
    if len(refined_components) > 4:
        return None

    return refined_components

def main():
    print("ğŸ”„ è¾æ›¸ã‚’è‡ªå‹•ç”Ÿæˆä¸­ï¼ˆJSONè¨­å®šèª­è¾¼ãƒ¢ãƒ¼ãƒ‰ï¼‰...")
    
    # 1. è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿
    ATOMIC_PARTS, MANUAL_OVERRIDES = load_config()

    allowed_set = load_joyo_kanji(ATOMIC_PARTS)
    ids_db = parse_ids_file(INPUT_IDS_FILE)
    final_dictionary = {}
    
    # 2. æ‰‹å‹•ã‚ªãƒ¼ãƒãƒ¼ãƒ©ã‚¤ãƒ‰ã‚’é©ç”¨
    for k, v in MANUAL_OVERRIDES.items():
        final_dictionary[k] = v

    # 3. è‡ªå‹•åˆ†è§£
    count = 0
    for kanji in allowed_set:
        if kanji in final_dictionary: continue
        if kanji in ATOMIC_PARTS: continue

        # atomic_partsã‚‚æ¸¡ã™
        clean_parts = deep_decompose(kanji, ids_db, allowed_set, ATOMIC_PARTS)
        
        # 2ã€œ4è¦ç´ ãªã‚‰æ¡ç”¨
        if clean_parts and 2 <= len(clean_parts) <= 4:
            if len(clean_parts) == 2:
                final_dictionary[kanji] = clean_parts
            else:
                # 3è¦ç´ ä»¥ä¸Šã¯ä¸­é–“ãƒ‘ãƒ¼ãƒ„åŒ– ( [A, B, C] -> A + &BC )
                current_parts = clean_parts[:]
                intermediate_base = f"&{kanji}"
                step = 0
                
                while len(current_parts) > 2:
                    p1 = current_parts.pop(0)
                    p2 = current_parts.pop(0)
                    inter_id = f"{intermediate_base}_{step}"
                    step += 1
                    
                    final_dictionary[inter_id] = [p1, p2]
                    current_parts.insert(0, inter_id)
                
                final_dictionary[kanji] = current_parts
            count += 1

    print(f"ğŸ“¦ ç”Ÿæˆå®Œäº†: {len(final_dictionary)} æ¼¢å­—")
    
    os.makedirs(os.path.dirname(OUTPUT_JSON_FILE), exist_ok=True)
    with open(OUTPUT_JSON_FILE, "w", encoding="utf-8") as f:
        json.dump(final_dictionary, f, ensure_ascii=False, indent=2)

if __name__ == "__main__":
    main()